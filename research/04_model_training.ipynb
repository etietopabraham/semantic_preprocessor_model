{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/macbookpro/Documents/semantic_preprocessor_model/semantic_preprocessor_model'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Configuration related to model training\n",
    "model_training:\n",
    "  # Directory where model training results and artifacts are stored\n",
    "  root_dir: artifacts/model_trainer\n",
    "  \n",
    "  # Path to the train features\n",
    "  train_features_path: artifacts/data_transformation/train_features.npz\n",
    "\n",
    "  # Path to the test data\n",
    "  test_features_path: artifacts/data_transformation/test_features.npz\n",
    "\n",
    "  # Path to train labels\n",
    "  train_labels_path: artifacts/data_transformation/train_labels.csv\n",
    "\n",
    "  # Path to test labels\n",
    "  test_labels_path: artifacts/data_transformation/test_labels.csv\n",
    "\n",
    "  # Path to save our model\n",
    "  model_name: model.joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainingConfig:\n",
    "    \"\"\"\n",
    "    Configuration class for model training using the MLPClassifier neural network.\n",
    "\n",
    "    Attributes:\n",
    "    - root_dir: Directory for storing model training results and related artifacts.\n",
    "    - train_features_path: Path to the features of the training dataset.\n",
    "    - train_labels_path: Path to the labels of the training dataset.\n",
    "    - test_features_path: Path to the features of the test dataset.\n",
    "    - test_labels_path: Path to the labels of the test dataset.\n",
    "    - model_name: Name or path under which the trained model will be saved.\n",
    "    - hidden_layer_sizes: Number of neurons in each hidden layer.\n",
    "    - max_iter: Maximum number of iterations for the solver to converge.\n",
    "    - random_state: Seed for reproducibility.\n",
    "    \"\"\"\n",
    "    \n",
    "    root_dir: Path  # Directory for storing model training results and related artifacts\n",
    "    train_features_path: Path  # Path to the train features\n",
    "    train_labels_path: Path  # Path to train labels\n",
    "    test_features_path: Path  # Path to the test features\n",
    "    test_labels_path: Path  # Path to test labels\n",
    "    model_name: str  # Name or path where the trained model should be saved\n",
    "    \n",
    "    hidden_layer_sizes: tuple  # Number of neurons in each hidden layer (e.g., (100,) for one hidden layer with 100 neurons)\n",
    "    max_iter: int  # Maximum number of iterations for the solver to converge\n",
    "    random_state: int  # Seed for reproducibility\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "MLPClassifier:\n",
    "  # Number of neurons in each hidden layer. For instance, (100,) denotes one hidden layer with 100 neurons.\n",
    "  hidden_layer_sizes: (100,)\n",
    "  \n",
    "  # Maximum number of iterations for the solver to converge.\n",
    "  max_iter: 500\n",
    "  \n",
    "  # A seed for reproducibility.\n",
    "  random_state: 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.semantic_preprocessor_model.constants import *\n",
    "from src.semantic_preprocessor_model.utils.common import read_yaml, create_directories\n",
    "from src.semantic_preprocessor_model import logger\n",
    "from src.semantic_preprocessor_model.entity.config_entity import DataValidationConfig, DataTransformationConfig, DataValidationConfig, ModelTrainingConfig\n",
    "import os\n",
    "\n",
    "class ConfigurationManager:\n",
    "    \"\"\"\n",
    "    The ConfigurationManager manages configuration settings needed throughout the data \n",
    "    pipeline processes, such as data validation and data transformation.\n",
    "\n",
    "    It reads configuration, parameter, and schema settings from specified files and provides \n",
    "    a set of methods to access these settings. Additionally, it ensures that the required \n",
    "    directories specified in the configurations are created.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 config_filepath=CONFIG_FILE_PATH, \n",
    "                 params_filepath=PARAMS_FILE_PATH, \n",
    "                 schema_filepath=SCHEMA_FILE_PATH) -> None:\n",
    "        \"\"\"\n",
    "        Initialize ConfigurationManager with configurations, parameters, and schema.\n",
    "\n",
    "        Args:\n",
    "        - config_filepath (Path): Path to the configuration file.\n",
    "        - params_filepath (Path): Path to the parameters file.\n",
    "        - schema_filepath (Path): Path to the schema file.\n",
    "\n",
    "        Creates:\n",
    "        - Directories specified in the configuration, if they don't exist.\n",
    "        \"\"\"\n",
    "        self.config = self._read_config_file(config_filepath, \"config\")\n",
    "        self.params = self._read_config_file(params_filepath, \"params\")\n",
    "        self.schema = self._read_config_file(schema_filepath, \"schema\")\n",
    "\n",
    "        # Ensure the directory for storing artifacts exists\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def _read_config_file(self, filepath: str, config_name: str) -> dict:\n",
    "        \"\"\"\n",
    "        Read and return the content of a configuration file.\n",
    "\n",
    "        Args:\n",
    "        - filepath (str): Path to the configuration file.\n",
    "        - config_name (str): Name of the configuration (for logging purposes).\n",
    "\n",
    "        Returns:\n",
    "        - dict: Content of the configuration file.\n",
    "\n",
    "        Raises:\n",
    "        - Exception: If there's an error reading the file.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return read_yaml(filepath)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading {config_name} file: {filepath}. Error: {e}\")\n",
    "            raise\n",
    "\n",
    "    def get_model_training_config(self) -> ModelTrainingConfig:\n",
    "        \"\"\"\n",
    "        Construct and return a configuration object for model training using the MLPClassifier.\n",
    "\n",
    "        Returns:\n",
    "        - ModelTrainerConfig: Configuration object for model training.\n",
    "\n",
    "        Raises:\n",
    "        - AttributeError: If an expected attribute does not exist in the config or params files.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            config = self.config.model_training\n",
    "            params = self.params.MLPClassifier\n",
    "\n",
    "            # Ensure the root directory for model training exists\n",
    "            create_directories([config.root_dir])\n",
    "\n",
    "            # Construct and return the ModelTrainerConfig object\n",
    "            return ModelTrainingConfig(\n",
    "                root_dir=Path(config.root_dir),\n",
    "                train_features_path=Path(config.train_features_path),\n",
    "                train_labels_path=Path(config.train_labels_path),\n",
    "                test_features_path=Path(config.test_features_path),\n",
    "                test_labels_path=Path(config.test_labels_path),\n",
    "                model_name=config.model_name,\n",
    "                random_state=params.random_state,\n",
    "                hidden_layer_sizes=params.hidden_layer_sizes,\n",
    "                max_iter=params.max_iter,\n",
    "            )\n",
    "\n",
    "        except AttributeError as e:\n",
    "            # Log the error and re-raise the exception for handling by the caller\n",
    "            logger.error(\"An expected attribute does not exist in the config or params files.\")\n",
    "            raise e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from src.semantic_preprocessor_model.config.configuration import ConfigurationManager\n",
    "from scipy.sparse import load_npz\n",
    "import joblib\n",
    "import os\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "\n",
    "class ModelTraining:\n",
    "    \"\"\"\n",
    "    ModelTraining is responsible for training a machine learning model based on the \n",
    "    provided configuration. It uses the MLPClassifier to train a neural network model \n",
    "    on the processed and transformed data.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: ConfigurationManager):\n",
    "        \"\"\"\n",
    "        Initializes the ModelTraining component.\n",
    "        \n",
    "        Args:\n",
    "        - config (ConfigurationManager): Configuration settings for model training.\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Train the model using the transformed data. The method loads the training data, \n",
    "        initializes the MLPClassifier with the specified parameters, trains the classifier, \n",
    "        and then saves the trained model to the specified path.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Load training data\n",
    "        X_train = load_npz(self.config.train_features_path)\n",
    "        y_train = pd.read_csv(self.config.train_labels_path).iloc[:, 0]\n",
    "\n",
    "        # Convert string representation of tuple to actual tuple\n",
    "        hidden_layer_sizes_tuple = ast.literal_eval(self.config.hidden_layer_sizes)\n",
    "\n",
    "        params = {\n",
    "            'hidden_layer_sizes': hidden_layer_sizes_tuple,\n",
    "            'max_iter': self.config.max_iter,\n",
    "            'random_state': self.config.random_state\n",
    "        }\n",
    "\n",
    "        # Initialize a Neural Network classifier with the specified parameters\n",
    "        nn_classifier_general = MLPClassifier(**params, verbose=True)\n",
    "\n",
    "        print(X_train.shape[0])\n",
    "        print(len(y_train))\n",
    "\n",
    "        print(self.config.hidden_layer_sizes)\n",
    "        print(type(self.config.hidden_layer_sizes))\n",
    "\n",
    "        # Train the Neural Network classifier\n",
    "        nn_classifier_general.fit(X_train, y_train)\n",
    "\n",
    "        # Save the trained model\n",
    "        model_save_path = os.path.join(self.config.root_dir, self.config.model_name)\n",
    "        joblib.dump(nn_classifier_general, model_save_path)\n",
    "        logger.info(f\"Model saved successfully to {model_save_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-23 00:33:26,750: 42: semantic_preprocessor_model_logger: INFO: common:  yaml file: config/config.yaml loaded successfully]\n",
      "[2023-10-23 00:33:26,752: 42: semantic_preprocessor_model_logger: INFO: common:  yaml file: params.yaml loaded successfully]\n",
      "[2023-10-23 00:33:26,754: 42: semantic_preprocessor_model_logger: INFO: common:  yaml file: schema.yaml loaded successfully]\n",
      "[2023-10-23 00:33:26,755: 65: semantic_preprocessor_model_logger: INFO: common:  Created directory at: artifacts]\n",
      "[2023-10-23 00:33:26,755: 53: semantic_preprocessor_model_logger: INFO: 2216604145:  Starting the Model Training Pipeline.]\n",
      "[2023-10-23 00:33:26,756: 54: semantic_preprocessor_model_logger: INFO: 2216604145:  >>>>>> Stage: Model Training Pipeline started <<<<<<]\n",
      "[2023-10-23 00:33:26,757: 30: semantic_preprocessor_model_logger: INFO: 2216604145:  Fetching model training configuration...]\n",
      "[2023-10-23 00:33:26,757: 65: semantic_preprocessor_model_logger: INFO: common:  Created directory at: artifacts/model_trainer]\n",
      "[2023-10-23 00:33:26,758: 33: semantic_preprocessor_model_logger: INFO: 2216604145:  Initializing model training process...]\n",
      "[2023-10-23 00:33:26,758: 36: semantic_preprocessor_model_logger: INFO: 2216604145:  Executing model training...]\n",
      "237484\n",
      "237484\n",
      "(100,)\n",
      "<class 'str'>\n",
      "Iteration 1, loss = 0.91719097\n",
      "Iteration 2, loss = 0.10835058\n",
      "Iteration 3, loss = 0.05979906\n",
      "Iteration 4, loss = 0.04254159\n",
      "Iteration 5, loss = 0.03473599\n",
      "Iteration 6, loss = 0.03079430\n",
      "Iteration 7, loss = 0.02823939\n",
      "Iteration 8, loss = 0.02659271\n",
      "Iteration 9, loss = 0.02551785\n",
      "Iteration 10, loss = 0.02469736\n",
      "Iteration 11, loss = 0.02405773\n",
      "Iteration 12, loss = 0.02358222\n",
      "Iteration 13, loss = 0.02317971\n",
      "Iteration 14, loss = 0.02290195\n",
      "Iteration 15, loss = 0.02261905\n",
      "Iteration 16, loss = 0.02238719\n",
      "Iteration 17, loss = 0.02222865\n",
      "Iteration 18, loss = 0.02211214\n",
      "Iteration 19, loss = 0.02193488\n",
      "Iteration 20, loss = 0.02191331\n",
      "Iteration 21, loss = 0.02172508\n",
      "Iteration 22, loss = 0.02160890\n",
      "Iteration 23, loss = 0.02152344\n",
      "Iteration 24, loss = 0.02157221\n",
      "Iteration 25, loss = 0.02147592\n",
      "Iteration 26, loss = 0.02129235\n",
      "Iteration 27, loss = 0.02131206\n",
      "Iteration 28, loss = 0.02117690\n",
      "Iteration 29, loss = 0.02120097\n",
      "Iteration 30, loss = 0.02109692\n",
      "Iteration 31, loss = 0.02094066\n",
      "Iteration 32, loss = 0.02109787\n",
      "Iteration 33, loss = 0.02107792\n",
      "Iteration 34, loss = 0.02090197\n",
      "Iteration 35, loss = 0.02100919\n",
      "Iteration 36, loss = 0.02084005\n",
      "Iteration 37, loss = 0.02094718\n",
      "Iteration 38, loss = 0.02068389\n",
      "Iteration 39, loss = 0.02077857\n",
      "Iteration 40, loss = 0.02080308\n",
      "Iteration 41, loss = 0.02062069\n",
      "Iteration 42, loss = 0.02067688\n",
      "Iteration 43, loss = 0.02062525\n",
      "Iteration 44, loss = 0.02063491\n",
      "Iteration 45, loss = 0.02065073\n",
      "Iteration 46, loss = 0.02059968\n",
      "Iteration 47, loss = 0.02054004\n",
      "Iteration 48, loss = 0.02048045\n",
      "Iteration 49, loss = 0.02051294\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "[2023-10-23 01:03:54,560: 62: semantic_preprocessor_model_logger: INFO: 1102614814:  Model saved successfully to artifacts/model_trainer/model.joblib]\n",
      "[2023-10-23 01:03:54,572: 39: semantic_preprocessor_model_logger: INFO: 2216604145:  Model Training Pipeline completed successfully.]\n",
      "[2023-10-23 01:03:54,573: 56: semantic_preprocessor_model_logger: INFO: 2216604145:  >>>>>> Stage Model Training Pipeline completed <<<<<< \n",
      "\n",
      "x==========x]\n"
     ]
    }
   ],
   "source": [
    "from src.semantic_preprocessor_model import logger\n",
    "\n",
    "class ModelTrainerPipeline:\n",
    "    \"\"\"\n",
    "    This pipeline handles the model training process.\n",
    "\n",
    "    After the data transformation stage, this class orchestrates the training of the model\n",
    "    using the GradientBoostingRegressor and saves the trained model for future use.\n",
    "\n",
    "    Attributes:\n",
    "        STAGE_NAME (str): The name of this pipeline stage.\n",
    "    \"\"\"\n",
    "    \n",
    "    STAGE_NAME = \"Model Training Pipeline\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the pipeline with a configuration manager.\n",
    "        \"\"\"\n",
    "        self.config_manager = ConfigurationManager()\n",
    "\n",
    "    def run_model_training(self):\n",
    "        \"\"\"\n",
    "        Orchestrates the model training process.\n",
    "\n",
    "        Fetches configurations, initializes the model training process, trains the model,\n",
    "        and logs the successful completion of the training.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logger.info(\"Fetching model training configuration...\")\n",
    "            model_training_configuration = self.config_manager.get_model_training_config()\n",
    "\n",
    "            logger.info(\"Initializing model training process...\")\n",
    "            model_training = ModelTraining(config=model_training_configuration)\n",
    "\n",
    "            logger.info(\"Executing model training...\")\n",
    "            model_training.train()\n",
    "\n",
    "            logger.info(\"Model Training Pipeline completed successfully.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error encountered during the model training: {e}\")\n",
    "\n",
    "    \n",
    "    def run_pipeline(self):\n",
    "        \"\"\"\n",
    "        Run the entire Model Training Pipeline.\n",
    "\n",
    "        This method orchestrates the process of model training and provides logs for each stage \n",
    "        of the pipeline.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logger.info(\"Starting the Model Training Pipeline.\")\n",
    "            logger.info(f\">>>>>> Stage: {ModelTrainerPipeline.STAGE_NAME} started <<<<<<\")\n",
    "            self.run_model_training()\n",
    "            logger.info(f\">>>>>> Stage {ModelTrainerPipeline.STAGE_NAME} completed <<<<<< \\n\\nx==========x\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error encountered during the {ModelTrainerPipeline.STAGE_NAME}: {e}\")\n",
    "            raise e\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pipeline = ModelTrainerPipeline()\n",
    "    pipeline.run_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semantic_preprocessor_model_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
