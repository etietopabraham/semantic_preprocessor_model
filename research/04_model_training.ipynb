{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/macbookpro/Documents/semantic_preprocessor_model/semantic_preprocessor_model'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Configuration related to model training\n",
    "model_training:\n",
    "  # Directory where model training results and artifacts are stored\n",
    "  root_dir: artifacts/model_trainer\n",
    "  \n",
    "  # Path to the train features\n",
    "  train_features_path: artifacts/data_transformation/train_features.npz\n",
    "  \n",
    "  # Path to the validation features\n",
    "  val_features_path: artifacts/data_transformation/val_features.npz\n",
    "  \n",
    "  # Path to train labels\n",
    "  train_labels_path: artifacts/data_transformation/train_labels.csv\n",
    "  \n",
    "  # Path to validation labels\n",
    "  val_labels_path: artifacts/data_transformation/val_labels.csv\n",
    "  \n",
    "  # Path to save the trained model\n",
    "  model_name: model.joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainingConfig:\n",
    "    \"\"\"\n",
    "    Configuration class for model training using the MLPClassifier neural network.\n",
    "\n",
    "    Attributes:\n",
    "    - root_dir: Directory for storing model training results and related artifacts.\n",
    "    - train_features_path: Path to the features of the training dataset.\n",
    "    - train_labels_path: Path to the labels of the training dataset.\n",
    "    - val_features_path: Path to the features of the validation dataset.\n",
    "    - val_labels_path: Path to the labels of the validation dataset.\n",
    "    - model_name: Name or path under which the trained model will be saved.\n",
    "    - hidden_layer_sizes: Number of neurons in each hidden layer.\n",
    "    - max_iter: Maximum number of iterations for the solver to converge.\n",
    "    - random_state: Seed for reproducibility.\n",
    "    \"\"\"\n",
    "    \n",
    "    root_dir: Path  # Directory for storing model training results and related artifacts\n",
    "    train_features_path: Path  # Path to the features of the training dataset\n",
    "    train_labels_path: Path  # Path to the labels of the training dataset\n",
    "    val_features_path: Path  # Path to the features of the validation dataset\n",
    "    val_labels_path: Path  # Path to the labels of the validation dataset\n",
    "    model_name: str  # Name or path where the trained model should be saved\n",
    "    \n",
    "    hidden_layer_sizes: tuple  # Number of neurons in each hidden layer\n",
    "    max_iter: int  # Maximum number of iterations for the solver to converge\n",
    "    random_state: int  # Seed for reproducibility\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "MLPClassifier:\n",
    "  # Number of neurons in each hidden layer. For instance, (100,) denotes one hidden layer with 100 neurons.\n",
    "  hidden_layer_sizes: (100,)\n",
    "  \n",
    "  # Maximum number of iterations for the solver to converge.\n",
    "  max_iter: 500\n",
    "  \n",
    "  # A seed for reproducibility.\n",
    "  random_state: 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.semantic_preprocessor_model.constants import *\n",
    "from src.semantic_preprocessor_model.utils.common import read_yaml, create_directories\n",
    "from src.semantic_preprocessor_model import logger\n",
    "from src.semantic_preprocessor_model.entity.config_entity import  ModelTrainingConfig\n",
    "import os\n",
    "\n",
    "class ConfigurationManager:\n",
    "    \"\"\"\n",
    "    The ConfigurationManager manages configuration settings needed throughout the data \n",
    "    pipeline processes, such as data validation and data transformation.\n",
    "\n",
    "    It reads configuration, parameter, and schema settings from specified files and provides \n",
    "    a set of methods to access these settings. Additionally, it ensures that the required \n",
    "    directories specified in the configurations are created.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 config_filepath=CONFIG_FILE_PATH, \n",
    "                 params_filepath=PARAMS_FILE_PATH, \n",
    "                 schema_filepath=SCHEMA_FILE_PATH) -> None:\n",
    "        \"\"\"\n",
    "        Initialize ConfigurationManager with configurations, parameters, and schema.\n",
    "\n",
    "        Args:\n",
    "        - config_filepath (Path): Path to the configuration file.\n",
    "        - params_filepath (Path): Path to the parameters file.\n",
    "        - schema_filepath (Path): Path to the schema file.\n",
    "\n",
    "        Creates:\n",
    "        - Directories specified in the configuration, if they don't exist.\n",
    "        \"\"\"\n",
    "        self.config = self._read_config_file(config_filepath, \"config\")\n",
    "        self.params = self._read_config_file(params_filepath, \"params\")\n",
    "        self.schema = self._read_config_file(schema_filepath, \"schema\")\n",
    "\n",
    "        # Ensure the directory for storing artifacts exists\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def _read_config_file(self, filepath: str, config_name: str) -> dict:\n",
    "        \"\"\"\n",
    "        Read and return the content of a configuration file.\n",
    "\n",
    "        Args:\n",
    "        - filepath (str): Path to the configuration file.\n",
    "        - config_name (str): Name of the configuration (for logging purposes).\n",
    "\n",
    "        Returns:\n",
    "        - dict: Content of the configuration file.\n",
    "\n",
    "        Raises:\n",
    "        - Exception: If there's an error reading the file.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return read_yaml(filepath)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading {config_name} file: {filepath}. Error: {e}\")\n",
    "            raise\n",
    "\n",
    "    def get_model_training_config(self) -> ModelTrainingConfig:\n",
    "        \"\"\"\n",
    "        Construct and return a configuration object for model training using the MLPClassifier.\n",
    "\n",
    "        Returns:\n",
    "        - ModelTrainerConfig: Configuration object for model training.\n",
    "\n",
    "        Raises:\n",
    "        - AttributeError: If an expected attribute does not exist in the config or params files.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            config = self.config.model_training\n",
    "            params = self.params.MLPClassifier\n",
    "\n",
    "            # Ensure the root directory for model training exists\n",
    "            create_directories([config.root_dir])\n",
    "\n",
    "            # Construct and return the ModelTrainerConfig object\n",
    "            return ModelTrainingConfig(\n",
    "                root_dir=Path(config.root_dir),\n",
    "                train_features_path=Path(config.train_features_path),\n",
    "                train_labels_path=Path(config.train_labels_path),\n",
    "                val_features_path=Path(config.val_features_path),\n",
    "                val_labels_path=Path(config.val_labels_path),\n",
    "                model_name=config.model_name,\n",
    "                random_state=params.random_state,\n",
    "                hidden_layer_sizes=params.hidden_layer_sizes,\n",
    "                max_iter=params.max_iter,\n",
    "            )\n",
    "\n",
    "        except AttributeError as e:\n",
    "            # Log the error and re-raise the exception for handling by the caller\n",
    "            logger.error(\"An expected attribute does not exist in the config or params files.\")\n",
    "            raise e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from src.semantic_preprocessor_model.config.configuration import ConfigurationManager\n",
    "from scipy.sparse import load_npz\n",
    "import joblib\n",
    "import os\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "\n",
    "class ModelTraining:\n",
    "    \"\"\"\n",
    "    ModelTraining is responsible for training a machine learning model based on the \n",
    "    provided configuration. It uses the MLPClassifier to train a neural network model \n",
    "    on the processed and transformed data.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: ConfigurationManager):\n",
    "        \"\"\"\n",
    "        Initializes the ModelTraining component.\n",
    "        \n",
    "        Args:\n",
    "        - config (ConfigurationManager): Configuration settings for model training.\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Train the model using the transformed data. The method loads the training data, \n",
    "        initializes the MLPClassifier with the specified parameters, trains the classifier, \n",
    "        and then saves the trained model to the specified path.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Load training data\n",
    "        X_train = load_npz(self.config.train_features_path)\n",
    "        y_train = pd.read_csv(self.config.train_labels_path).iloc[:, 0]\n",
    "\n",
    "        # Convert string representation of tuple to actual tuple\n",
    "        hidden_layer_sizes_tuple = ast.literal_eval(self.config.hidden_layer_sizes)\n",
    "\n",
    "        params = {\n",
    "            'hidden_layer_sizes': hidden_layer_sizes_tuple,\n",
    "            'max_iter': self.config.max_iter,\n",
    "            'random_state': self.config.random_state\n",
    "        }\n",
    "\n",
    "        # Initialize a Neural Network classifier with the specified parameters\n",
    "        nn_classifier_general = MLPClassifier(**params, verbose=True)\n",
    "\n",
    "        print(X_train.shape[0])\n",
    "        print(len(y_train))\n",
    "\n",
    "        print(self.config.hidden_layer_sizes)\n",
    "        print(type(self.config.hidden_layer_sizes))\n",
    "\n",
    "        # Train the Neural Network classifier\n",
    "        nn_classifier_general.fit(X_train, y_train)\n",
    "\n",
    "        # Save the trained model\n",
    "        model_save_path = os.path.join(self.config.root_dir, self.config.model_name)\n",
    "        joblib.dump(nn_classifier_general, model_save_path)\n",
    "        logger.info(f\"Model saved successfully to {model_save_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-23 01:44:48,090: 42: semantic_preprocessor_model_logger: INFO: common:  yaml file: config/config.yaml loaded successfully]\n",
      "[2023-10-23 01:44:48,091: 42: semantic_preprocessor_model_logger: INFO: common:  yaml file: params.yaml loaded successfully]\n",
      "[2023-10-23 01:44:48,093: 42: semantic_preprocessor_model_logger: INFO: common:  yaml file: schema.yaml loaded successfully]\n",
      "[2023-10-23 01:44:48,094: 65: semantic_preprocessor_model_logger: INFO: common:  Created directory at: artifacts]\n",
      "[2023-10-23 01:44:48,094: 53: semantic_preprocessor_model_logger: INFO: 2216604145:  Starting the Model Training Pipeline.]\n",
      "[2023-10-23 01:44:48,094: 54: semantic_preprocessor_model_logger: INFO: 2216604145:  >>>>>> Stage: Model Training Pipeline started <<<<<<]\n",
      "[2023-10-23 01:44:48,095: 30: semantic_preprocessor_model_logger: INFO: 2216604145:  Fetching model training configuration...]\n",
      "[2023-10-23 01:44:48,095: 65: semantic_preprocessor_model_logger: INFO: common:  Created directory at: artifacts/model_trainer]\n",
      "[2023-10-23 01:44:48,095: 33: semantic_preprocessor_model_logger: INFO: 2216604145:  Initializing model training process...]\n",
      "[2023-10-23 01:44:48,096: 36: semantic_preprocessor_model_logger: INFO: 2216604145:  Executing model training...]\n",
      "237484\n",
      "237484\n",
      "(100,)\n",
      "<class 'str'>\n",
      "[2023-10-23 01:45:11,002: 62: semantic_preprocessor_model_logger: INFO: 1102614814:  Model saved successfully to artifacts/model_trainer/model.joblib]\n",
      "[2023-10-23 01:45:11,007: 39: semantic_preprocessor_model_logger: INFO: 2216604145:  Model Training Pipeline completed successfully.]\n",
      "[2023-10-23 01:45:11,008: 56: semantic_preprocessor_model_logger: INFO: 2216604145:  >>>>>> Stage Model Training Pipeline completed <<<<<< \n",
      "\n",
      "x==========x]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbookpro/miniconda3/envs/semantic_preprocessor_model_env/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    }
   ],
   "source": [
    "from src.semantic_preprocessor_model import logger\n",
    "\n",
    "class ModelTrainerPipeline:\n",
    "    \"\"\"\n",
    "    This pipeline handles the model training process.\n",
    "\n",
    "    After the data transformation stage, this class orchestrates the training of the model\n",
    "    using the GradientBoostingRegressor and saves the trained model for future use.\n",
    "\n",
    "    Attributes:\n",
    "        STAGE_NAME (str): The name of this pipeline stage.\n",
    "    \"\"\"\n",
    "    \n",
    "    STAGE_NAME = \"Model Training Pipeline\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the pipeline with a configuration manager.\n",
    "        \"\"\"\n",
    "        self.config_manager = ConfigurationManager()\n",
    "\n",
    "    def run_model_training(self):\n",
    "        \"\"\"\n",
    "        Orchestrates the model training process.\n",
    "\n",
    "        Fetches configurations, initializes the model training process, trains the model,\n",
    "        and logs the successful completion of the training.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logger.info(\"Fetching model training configuration...\")\n",
    "            model_training_configuration = self.config_manager.get_model_training_config()\n",
    "\n",
    "            logger.info(\"Initializing model training process...\")\n",
    "            model_training = ModelTraining(config=model_training_configuration)\n",
    "\n",
    "            logger.info(\"Executing model training...\")\n",
    "            model_training.train()\n",
    "\n",
    "            logger.info(\"Model Training Pipeline completed successfully.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error encountered during the model training: {e}\")\n",
    "\n",
    "    \n",
    "    def run_pipeline(self):\n",
    "        \"\"\"\n",
    "        Run the entire Model Training Pipeline.\n",
    "\n",
    "        This method orchestrates the process of model training and provides logs for each stage \n",
    "        of the pipeline.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logger.info(\"Starting the Model Training Pipeline.\")\n",
    "            logger.info(f\">>>>>> Stage: {ModelTrainerPipeline.STAGE_NAME} started <<<<<<\")\n",
    "            self.run_model_training()\n",
    "            logger.info(f\">>>>>> Stage {ModelTrainerPipeline.STAGE_NAME} completed <<<<<< \\n\\nx==========x\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error encountered during the {ModelTrainerPipeline.STAGE_NAME}: {e}\")\n",
    "            raise e\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pipeline = ModelTrainerPipeline()\n",
    "    pipeline.run_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semantic_preprocessor_model_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
